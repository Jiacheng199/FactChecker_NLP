{"cells":[{"cell_type":"markdown","metadata":{"id":"DYRV-S40oYZL"},"source":["## Load data (Cliams and evidences)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["data_path = \"data\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":21140,"status":"ok","timestamp":1725265924073,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"bApySGAb-gTa"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","\n","##evidences\n","evidence = pd.read_json(f'{data_path}/evidence.json',orient='index')\n","evidences = evidence.iloc[:,0].tolist()\n","\n","#development data\n","dev_data = pd.read_json(f'{data_path}/dev-claims.json',orient='index')\n","dev_claims = dev_data.iloc[:,0].tolist()\n","\n","#training data\n","train_data = pd.read_json(f'{data_path}/train-claims.json',orient='index')\n","train_claims = train_data.iloc[:,0].tolist()\n","\n","#testing data\n","test_data = pd.read_json(f'{data_path}/test-claims-unlabelled.json',orient='index')\n","test_claims = test_data.iloc[:,0].tolist()\n","\n","dev_baseline = pd.read_json(f'{data_path}/dev-claims-baseline.json',orient='index')\n"]},{"cell_type":"markdown","metadata":{"id":"CqrdGk28q0uj"},"source":["### Print out the Data structure"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1725265924074,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"-CkphLbko5JX","outputId":"35adee42-7100-40ca-d862-eff38d72d229"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Data columns: Index(['claim_text', 'claim_label', 'evidences'], dtype='object')\n","Shape: (1228, 3)\n","\n","Development Data columns: Index(['claim_text', 'claim_label', 'evidences'], dtype='object')\n","Shape: (154, 3)\n","\n","Testing Data columns: Index(['claim_text'], dtype='object')\n","Shape: (153, 1)\n","\n"]}],"source":["print(f\"Training Data columns: {train_data.columns}\")\n","print(f\"Shape: {train_data.shape}\\n\")\n","\n","print(f\"Development Data columns: {dev_data.columns}\")\n","print(f\"Shape: {dev_data.shape}\\n\")\n","\n","print(f\"Testing Data columns: {test_data.columns}\")\n","print(f\"Shape: {test_data.shape}\\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"w_iC0k8GPnFq"},"source":[]},{"cell_type":"markdown","metadata":{"id":"HOsel5yvQMqn"},"source":["# Retriever"]},{"cell_type":"markdown","metadata":{"id":"NeKjwrM4oPUt"},"source":["## DPR \n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"gWSe-PvR-Yhv"},"outputs":[],"source":["import torch\n","from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n","from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n","from tqdm import tqdm\n","\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","def evidences_dpr_embedding(evidences,batch_size=64):\n","\n","  # Load the models to GPU\n","  context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n","  context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n","\n","  context_embeddings = []\n","\n","  # Encoding\n","  for i in tqdm(range(0, len(evidences), batch_size), desc=\"Encoding Evidences\"):\n","      batch = evidences[i:i+batch_size]\n","      inputs = context_tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)  # 将输入移动到 GPU\n","\n","      with torch.no_grad():\n","          with torch.cuda.amp.autocast():\n","              embeddings = context_encoder(**inputs).pooler_output\n","          context_embeddings.append(embeddings.cpu())\n","\n","  #return embedding result as tensor\n","  context_embeddings = torch.cat(context_embeddings)\n","  return context_embeddings\n","\n","def claims_dpr_embedding(claims,batch_size=64):\n","\n","  # Load the models to GPU\n","  question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n","  question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n","\n","  question_embeddings = []\n","\n","  # Encoding\n","  for i in tqdm(range(0, len(claims), batch_size), desc=\"Encoding Claims\"):\n","      batch = claims[i:i+batch_size]\n","      inputs = question_tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n","\n","      with torch.no_grad():\n","          with torch.cuda.amp.autocast():\n","              embeddings = question_encoder(**inputs).pooler_output\n","              question_embeddings.append(embeddings.cpu())\n","\n","  #return embedding result as tensor\n","  question_embeddings = torch.cat(question_embeddings)\n","  return question_embeddings\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZmQsTGlHBeSX"},"source":["### Load DPR Embeddings of evidences and claims as tensors"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1724910781946,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"hCa-akBiJVMX","outputId":"8b180d0b-2f17-4df2-c4c3-b2d8aa2866e9"},"outputs":[],"source":["import torch\n","import pdb\n","from torch.nn.functional import cosine_similarity\n","\n","\"\"\"\n","Calculates cosine similarities between a claim embedding and a set of evidence embeddings,\n","returning the indices and scores of the top `n` most similar evidence embeddings.\n","\n","Input:\n","- claim_embedding: Tensor of shape [1, d], the embedding of the claim.\n","- evidence_embeddings: Tensor of shape [m, d], the embeddings of the evidence documents.\n","- n: Integer, the number of top similar evidence to return (default is 5).\n","\n","Returns:\n","- top_n_indices: List of integers, indices of the top `n` most similar evidence embeddings.\n","- top_n_scores: List of floats, cosine similarity scores of the top `n` most similar evidence embeddings.\n","\"\"\"\n","def find_top_n_evidence(claim_embedding, evidences_embeddings, n=5):\n","    scores = cosine_similarity(claim_embedding, evidences_embeddings)\n","    top_n_evidences = torch.topk(scores, k=n)\n","\n","    top_n_indices = top_n_evidences.indices.tolist()\n","    top_n_scores = top_n_evidences.values.tolist()\n","\n","    return top_n_indices, top_n_scores\n","\n","\n","\n","def dpr_search(claim_index, claim_embeddings, claim_data, evidences_embeddings, n=5):\n","    claim = claim_embeddings[claim_index].unsqueeze(0).to(device)\n","    best_evidence_indices, scores = find_top_n_evidence(claim, evidences_embeddings, n)\n","    print(f\"Best evidence indices: {best_evidence_indices}\\nScores: {scores}\\n\")\n","    print(f\"Claim: {claim_data.iloc[claim_index].iloc[0]}\\n\")\n","    print(f\"Label: {claim_data.iloc[claim_index].iloc[1]}\\n\")\n","    print(f\"Evidences: {claim_data.iloc[claim_index].iloc[2]}\\n\")\n","\n","    print(\"-- Best evidences --\\n\")\n","    for i in best_evidence_indices:\n","        print(f'evidence - {i}')\n","        print(evidences[i])\n","        print(\"============================\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"po-Srxz2zCVV"},"source":["## BM25"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rank_bm25 in ./.venv/lib/python3.10/site-packages (0.2.2)\n","Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from rank_bm25) (2.1.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install rank_bm25"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29137,"status":"ok","timestamp":1724913368179,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"tEvFwH7fzHFX","outputId":"27a245f6-0d20-4b8a-9f4f-ef47a9fdc1af"},"outputs":[],"source":["from rank_bm25 import BM25Okapi\n","corpus = evidences\n","\n","tokenized_corpus = [doc.split(\" \") for doc in corpus]\n","\n","bm25 = BM25Okapi(tokenized_corpus)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1273969,"status":"ok","timestamp":1724916389030,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"gsfc7Z_d1y7D","outputId":"34686471-c54e-4277-a6bf-40c3a574d721"},"outputs":[{"name":"stdout","output_type":"stream","text":["[\"After hearing Karim's opinion, Salhi would no longer speak with him other than to say hello and goodbye.\"]\n","[323573 218762  77646 ... 804894 804895 804886]\n","After hearing Karim's opinion, Salhi would no longer speak with him other than to say hello and goodbye.\n"]}],"source":["# for claim in tqdm(dev_claims[:3]):\n","#   print(claim,'\\n')\n","#   query = claim\n","#   tokenized_query = query.split(\" \")\n","\n","#   print(bm25.get_top_n(tokenized_query, corpus, n=3))\n","\n","tokenized_query = \"hello world\".split(\" \")\n","print(bm25.get_top_n(tokenized_query, corpus, n=1))\n","scores = bm25.get_scores(tokenized_query)\n","sorted_indexes = np.argsort(scores)[::-1]  \n","\n","print(sorted_indexes)\n","print(evidences[sorted_indexes[0]])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1724916753153,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"NngtKUjT3jVF","outputId":"8b4b61c7-08bb-49bb-9de4-b4a3372a1f40"},"outputs":[{"name":"stdout","output_type":"stream","text":["770\n","Match rate of n = 5\n","matched evidence/all finded evidence = 0.07402597402597402\n","matched evidence/number of evidence = 0.11608961303462322\n"]}],"source":["print(all_bm25_findings.size)\n","dev_evidences_list = np.concatenate(dev_data.iloc[:, 2].apply(lambda ev_list: [int(evidence.split('-')[1]) for evidence in ev_list]).values)\n","\n","print(f\"Match rate of n = {5}\")\n","print(f\"matched evidence/all finded evidence = {np.intersect1d(all_bm25_findings, dev_evidences_list).size/findings.size}\")\n","print(f\"matched evidence/number of evidence = {np.intersect1d(all_bm25_findings, dev_evidences_list).size/dev_evidences_list.size}\")"]},{"cell_type":"markdown","metadata":{"id":"G6vUACuuYrIS"},"source":[]},{"cell_type":"markdown","metadata":{"id":"vfXNXzVoYvsY"},"source":["## Sentence-BERT"]},{"cell_type":"markdown","metadata":{"id":"tCy3VTk4GTiD"},"source":["### Generating SBERT Embedding for claims and evidences"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"HmmxDsIvZSMV"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.10/site-packages (3.0.1)\n","Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (2.4.0+cu118)\n","Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (2.1.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.44.2)\n","Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\n","Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n","Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n","Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n","Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n","Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.9.0.58)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.8.87)\n","Requirement already satisfied: triton==3.0.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.0.86)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.8.89)\n","Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.11.3.6)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.5.86)\n","Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n","Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n","Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.8.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.1.48)\n","Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n","Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n","Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n","Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U sentence-transformers\n"]},{"cell_type":"markdown","metadata":{"id":"uzI_CKhQGiAm"},"source":["**Evidences** **Embedding**"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"imYuAEMEY66N"},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sentence_transformers import SentenceTransformer\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def sbert_embedding(sentences,batch_size=128):\n","  # 1. Load  Sentence BERT model\n","  model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n","\n","  dataloader = DataLoader(sentences, batch_size, shuffle=False)\n","\n","  embeddings = []\n","\n","  for batch in tqdm(dataloader, desc=\"Calculating embeddings in batches\"):\n","      batch_embeddings = model.encode(batch, convert_to_tensor=True, device=device)\n","      embeddings.append(batch_embeddings)\n","\n","  embeddings_tensor = torch.cat(embeddings, dim=0)\n","  return embeddings_tensor\n","\n","\n","\n","#torch.save(sbert_embedding(evidences), 'SBERT_evidences_embeddings.pt')\n"]},{"cell_type":"markdown","metadata":{"id":"7kmeKObiuWLY"},"source":["# Classifer"]},{"cell_type":"markdown","metadata":{"id":"Oq0LEJXubGHB"},"source":["## BERT-Based"]},{"cell_type":"markdown","metadata":{"id":"q6cGpaUNoldz"},"source":["### Load the necessary python packages"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2880,"status":"ok","timestamp":1725265926943,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"6QAvk4BmeCkt"},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspace/NLP_Factchecker/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["NVIDIA GeForce RTX 4090\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, AlbertTokenizer, AlbertForSequenceClassification\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","from tqdm import tqdm\n","import seaborn as sns\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification\n","import os\n","from datetime import datetime\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","gpu_name = torch.cuda.get_device_name(0)\n","print(gpu_name)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspace/NLP_Factchecker/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# RoBerta model for finetuning\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3).to(device)\n","\n","# Bert base model for finetuning\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n"]},{"cell_type":"markdown","metadata":{"id":"zR9xKACGbZiD"},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["f912bc64d9974701aa7c6c65529b2760","73f64b9ca87045a3a212a6616e264f8a","2db0df92d86d4a00841310accc900bb3","1ecd479b7f084fb6859fc7c8f757259d","648fafbe3a6a4822891303ea01d9e3d8","24c0d5bd34724e77a4f8040673542655","04fd4148d9734a259798326c35acb802","48e4351fa1eb466cbfcac0d73102c3c7","96dc0afd458b45d4bcb84920cd8540b9","4e1d0947e9d04a0a963df84cd960b908","a289b021fbe84beba8d7b98ecb5fe741","53095e476ee34357908961aef028a2da","86daca5476fc43e89e09e3780a249688","c0c37339d87a4ac8bcee6af538a8b97e","5d680862727c427984ed1cf1a633dc9c","6bd4173bff714866b471a8aaddd432c2","4fe9150319d8442385b6d1abfcc8b4b6","f27a7be4b1fa4995aa76a9c10af40c58","3d1d90c4067a4aed992f46f31dc47082","c37edaefdd484f198bdeb66d4c2b4bc9","1e94996ae09649deb9440e04938df8b3","faf3e5328edf4f8f959704c6a5d7573a","22ab6ffa6aff450f9b38609728f1a41b","8337b05dfba542b18af1d9374cca7727","95b7dac8ffe045809fd8899fb7e2713d","cb0d7371eaec47c8b9ae1e4fe159174d","b1620b45ffc94b79aa958acfa2fd0f5d","f11de9e3e8b54d959ee8d054b7666e16","c2cdfa7f3fc84987b7cb9d3b020b289c","006938b3be4d46f1afed4df75fc96121","fd56dc2785c049dd85bb8c559491ee5b","43c4a4cd5d6f46ed9975045e5c6ef79d","dea06e904af84aa7a2217d4a3982e4ea","dc41124288094fadb79e1eb1b46b2515","59d34d5ca14a442e89e364a2f8829d1b","fcb9516fd61c408c93d3da9de190dfe6","60dda5e87844400aa43e6f3a58e08a5e","0c88727a09b94d8a8033f4beed2bb030","93d77389ac58499589f14c3e66e659fc","767cc5ec12b14a8a8683cad02f2688db","c51bb68701f34118b1192470c4415e45","f9eb5043498c4aaabf4bc482e48260af","9f9153fbcd6040b19f49ccd92b69bf77","572de2a57015405ab5fa86e99e21299b"]},"executionInfo":{"elapsed":4523,"status":"ok","timestamp":1725265931460,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"HU4UxbmxQSuR","outputId":"4d3b147b-71e9-4b36-9ec6-9337c00df192"},"outputs":[],"source":["def extract_evidence_pairs_with_content(df, evidences_list, labels_of_interest=['SUPPORTS', 'REFUTES', 'NOT_ENOUGH_INFO']):\n","\n","    result_pairs = []\n","\n","    for index, row in df.iterrows():\n","        claim_text = row['claim_text']\n","        claim_label = row['claim_label']\n","        if claim_label in labels_of_interest:\n","            evidence_ids = row['evidences']\n","            for evidence_id in evidence_ids:\n","                evidence_content = evidences_list[int(evidence_id.split('-')[1])]\n","                result_pairs.append((claim_text, evidence_content, claim_label))\n","\n","    result_df = pd.DataFrame(result_pairs, columns=['claim_text', 'evidence', 'label'])\n","\n","    return result_df\n","\n","class ClaimEvidenceDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len=128):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        claim_text = str(self.data.iloc[idx]['claim_text'])\n","        evidence = str(self.data.iloc[idx]['evidence'])\n","        label = self.data.iloc[idx]['label']\n","\n","        encoding = self.tokenizer.encode_plus(\n","            claim_text,\n","            evidence,\n","            add_special_tokens=True,\n","            max_length=256,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            #'token_type_ids': encoding['token_type_ids'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","\n","model_train_data, model_val_data = train_test_split(train_data, test_size=0.1, random_state=12)\n","\n","pair_training_data = extract_evidence_pairs_with_content(model_train_data, evidences)\n","pair_val_data = extract_evidence_pairs_with_content(model_val_data, evidences)\n","pair_dev_data = extract_evidence_pairs_with_content(dev_data, evidences)\n","\n","label_map = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2}\n","pair_training_data['label'] = pair_training_data['label'].map(label_map)\n","pair_val_data['label'] = pair_val_data['label'].map(label_map)\n","pair_dev_data['label'] = pair_dev_data['label'].map(label_map)\n","\n","\n","train_dataset = ClaimEvidenceDataset(pair_training_data, tokenizer)\n","val_dataset = ClaimEvidenceDataset(pair_val_data, tokenizer)\n","dev_dataset = ClaimEvidenceDataset(pair_dev_data, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1725265931461,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"Fc4NQED-RZZl","outputId":"d864cb0e-2d4d-411d-c354-9f8e4f651217"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>claim_text</th>\n","      <th>evidence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>With that in mind, they propose a plausible an...</td>\n","      <td>Mind Meld: Secrets Behind the Voyage of a Life...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>With that in mind, they propose a plausible an...</td>\n","      <td>Naturalistic dualism comes from Australian phi...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>With that in mind, they propose a plausible an...</td>\n","      <td>Chalmers' argument is that it seems plausible ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>With that in mind, they propose a plausible an...</td>\n","      <td>The quantum mind or quantum consciousness is a...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>With that in mind, they propose a plausible an...</td>\n","      <td>He proposed a scenario with a cat in a locked ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          claim_text  \\\n","0  With that in mind, they propose a plausible an...   \n","1  With that in mind, they propose a plausible an...   \n","2  With that in mind, they propose a plausible an...   \n","3  With that in mind, they propose a plausible an...   \n","4  With that in mind, they propose a plausible an...   \n","\n","                                            evidence  label  \n","0  Mind Meld: Secrets Behind the Voyage of a Life...      2  \n","1  Naturalistic dualism comes from Australian phi...      2  \n","2  Chalmers' argument is that it seems plausible ...      2  \n","3  The quantum mind or quantum consciousness is a...      2  \n","4  He proposed a scenario with a cat in a locked ...      2  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# pair_training_data.to_json('/content/drive/MyDrive/Colab Notebooks/NLP project/FactChecker_NLP/pair_training_data.json')\n","pair_training_data.head()"]},{"cell_type":"markdown","metadata":{"id":"545wWcI3dyiz"},"source":["### BERT Model Training (Methods define)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1725265931461,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"a6LqEjeid8Cm"},"outputs":[],"source":["\n","def train_epoch(model, data_loader, optimizer, scheduler, device):\n","    model = model.train()\n","    losses = []\n","    correct_predictions = 0\n","\n","    loop = tqdm(data_loader, leave=True)\n","\n","    for batch in loop:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        #token_type_ids = batch['token_type_ids'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            #token_type_ids=token_type_ids,\n","            labels=labels\n","        )\n","\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        _, preds = torch.max(logits, dim=1)\n","        correct_predictions += torch.sum(preds == labels)\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","        loop.set_description(f\"Train Epoch [{epoch + 1}]\")\n","        loop.set_postfix(loss=loss.item())\n","\n","    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n","\n","def eval_model(model, data_loader, device):\n","    model.eval()\n","    losses = []\n","    correct_predictions = 0\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            #token_type_ids = batch['token_type_ids'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                #token_type_ids=token_type_ids,\n","                labels=labels\n","            )\n","\n","            loss = outputs.loss\n","            logits = outputs.logits\n","\n","            _, preds = torch.max(logits, dim=1)\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')  # 计算加权平均的F1分数\n","    report = classification_report(all_labels, all_preds, target_names=['SUPPORTS', 'REFUTES', 'NOT_ENOUGH_INFO'])\n","\n","    return accuracy, np.mean(losses), f1, report\n","\n","\n","\n","def save_model_and_metrics(model, optimizer, epoch, train_loss, train_accuracy, val_loss, val_accuracy, val_f1, val_report, save_dir, model_name):\n","    # Create save directory if it doesn't exist\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    # Generate timestamp\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","    # Prepare the data to be saved\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'train_loss': train_loss,\n","        'train_accuracy': train_accuracy,\n","        'val_loss': val_loss,\n","        'val_accuracy': val_accuracy,\n","        'val_f1': val_f1,\n","        'val_report': val_report\n","    }\n","\n","    # Save the checkpoint\n","    model_path = os.path.join(save_dir, f\"{model_name}_epoch-{epoch}.pt\")\n","    torch.save(checkpoint, model_path)\n","    print(f\"Model and metrics saved to {model_path}\")\n","\n","    return model_path\n","\n","\n","def load_model_and_metrics(model, optimizer, filepath):\n","    checkpoint = torch.load(filepath)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    \n","    # Print metrics\n","    print(f\"Epoch: {checkpoint['epoch']}\")\n","    print(f\"Train Loss: {checkpoint['train_loss']:.4f}\")\n","    print(f\"Train Accuracy: {checkpoint['train_accuracy']:.4f}\")\n","    print(f\"Validation Loss: {checkpoint['val_loss']:.4f}\")\n","    print(f\"Validation Accuracy: {checkpoint['val_accuracy']:.4f}\")\n","    print(f\"Validation F1 Score: {checkpoint['val_f1']:.4f}\")\n","    print(\"Validation Report:\")\n","    print(checkpoint['val_report'])\n","\n","    return model, optimizer\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NfJmBEvtu_ni"},"source":["### BERT Model Training (Hyper parms define, actual training, save the model to local)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"elapsed":215034,"status":"ok","timestamp":1725268010567,"user":{"displayName":"Jiacheng Wang","userId":"08806092138054227226"},"user_tz":-420},"id":"Y6qoEVsMe0Qf","outputId":"2a048599-85a0-47f5-baea-f0e3c2b2eb24"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","\n","\n","# Training loop\n","epochs = 10\n","patience = 3  # Number of epochs to wait for improvement before early stopping\n","best_val_acc = 0\n","no_improve_epoch = 0\n","\n","# Set Optimizer and Learning Rate Scheduler\n","optimizer = AdamW(model.parameters(), lr=5e-6, eps=1e-8)\n","\n","total_steps = len(train_loader) * epochs\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=int(0.2*total_steps),\n","    num_training_steps=total_steps\n",")\n","\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    print('-' * 20)\n","\n","    # Train the model\n","    train_acc, train_loss = train_epoch(\n","        model, train_loader, optimizer, scheduler, device\n","    )\n","\n","    print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","    # Validate the model\n","    val_acc, val_loss, val_f1, val_report = eval_model(\n","        model, val_loader, device\n","    )\n","\n","    print(f'Val   loss {val_loss} accuracy {val_acc}')\n","    print(f'Val F1 Score: {val_f1}')\n","    print(f'Val Classification Report:\\n{val_report}')\n","\n","    dev_acc, dev_loss, dev_f1, dev_report = eval_model(\n","        model, dev_loader, device\n","    )\n","\n","    print(f'Dev accuracy {dev_acc}')\n","    print(f'Dev F1 Score: {dev_f1}')\n","    print(f'Dev Classification Report:\\n{dev_report}')\n","\n","    # Check if this is the best model (based on validation accuracy)\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        no_improve_epoch = 0\n","        # Save the best model\n","        best_model_path = save_model_and_metrics(\n","            model, optimizer, epoch, train_loss, train_acc,\n","            val_loss, val_acc, val_f1, val_report,\n","            save_dir=\"./model_checkpoints\",\n","            model_name=type(model).__name__\n","        )\n","        print(f\"New best model saved with validation accuracy: {val_acc}\")\n","    else:\n","        no_improve_epoch += 1\n","\n","    # Early stopping\n","    if no_improve_epoch >= patience:\n","        print(f\"Early stopping triggered. No improvement for {patience} epochs.\")\n","        break\n","\n","print(\"Training completed.\")\n","print(f\"Best validation accuracy: {best_val_acc}\")\n","print(f\"Best model saved at: {best_model_path}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from sentence_transformers import util"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def check_array(arr):\n","    contains_0 = False\n","    contains_1 = False\n","    contains_2 = False\n","\n","    for num in arr:\n","        if num == 0:\n","            contains_0 = True\n","        elif num == 1:\n","            contains_1 = True\n","        elif num == 2:\n","            contains_2 = True\n","\n","    # 判断逻辑\n","    if contains_0 and contains_1:\n","        return 3\n","    elif contains_0:\n","        return 0\n","    elif contains_1:\n","        return 1\n","    elif contains_2 and not contains_0 and not contains_1:\n","        return 2\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_709/1643544345.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  SBERT_evidence_embeddings = torch.load('SBERT_evidences_embeddings.pt').to(device)\n"]},{"name":"stderr","output_type":"stream","text":["/workspace/NLP_Factchecker/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Calculating embeddings in batches: 100%|██████████| 2/2 [00:00<00:00, 32.05it/s]\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/workspace/NLP_Factchecker/.venv/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_709/793136328.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(filepath)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3\n","Train Loss: 0.5159\n","Train Accuracy: 0.8098\n","Validation Loss: 0.8772\n","Validation Accuracy: 0.6528\n","Validation F1 Score: 0.6499\n","Validation Report:\n","                 precision    recall  f1-score   support\n","\n","       SUPPORTS       0.72      0.64      0.68       140\n","        REFUTES       0.53      0.43      0.48        56\n","NOT_ENOUGH_INFO       0.64      0.73      0.68       190\n","\n","       accuracy                           0.65       386\n","      macro avg       0.63      0.60      0.61       386\n","   weighted avg       0.65      0.65      0.65       386\n","\n"]},{"name":"stderr","output_type":"stream","text":["3it [00:00, 22.91it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["9it [00:00, 23.22it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["12it [00:00, 23.18it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["15it [00:00, 23.47it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["18it [00:00, 23.46it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["24it [00:01, 23.65it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["27it [00:01, 23.54it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["30it [00:01, 23.55it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["33it [00:01, 23.65it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["39it [00:01, 23.63it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["42it [00:01, 23.55it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["45it [00:01, 23.59it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["48it [00:02, 23.62it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["54it [00:02, 23.65it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["57it [00:02, 23.65it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["60it [00:02, 23.64it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["63it [00:02, 23.56it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["69it [00:02, 23.71it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["72it [00:03, 23.64it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["75it [00:03, 23.63it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["78it [00:03, 23.74it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["84it [00:03, 23.74it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["87it [00:03, 23.69it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["90it [00:03, 23.67it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["93it [00:03, 23.65it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["99it [00:04, 23.85it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["102it [00:04, 23.87it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["105it [00:04, 23.80it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["108it [00:04, 23.86it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["114it [00:04, 23.94it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["117it [00:04, 23.81it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["120it [00:05, 23.82it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["123it [00:05, 23.91it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["129it [00:05, 23.93it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["132it [00:05, 23.87it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["135it [00:05, 23.90it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["138it [00:05, 23.83it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["144it [00:06, 23.92it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["147it [00:06, 23.81it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["150it [00:06, 23.82it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["154it [00:06, 23.70it/s]"]},{"name":"stdout","output_type":"stream","text":["prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n","prediction completed on : sbert\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["dev_data = pd.read_json(f'{data_path}/dev-claims.json',orient='index')\n","dev_claims = dev_data.iloc[:,0].tolist()\n","dev_data_pred = dev_data.copy(deep=True)\n","\n","#SBERT retriever loading\n","SBERT_evidence_embeddings = torch.load('SBERT_evidences_embeddings.pt').to(device)\n","claims_embedding = sbert_embedding(dev_claims).to(device)\n","\n","#DPR retriver loading\n","# DPR_evidence_embeddings = torch.load(f'{data_path}/dpr_evidences_embeddings.pt').to(device)\n","# DPR_claims_embeddings = claims_dpr_embedding(dev_claims).to(device)\n","\n","#Roberta classifer model loading\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3).to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-6, eps=1e-8)\n","best_model_path = \"model_checkpoints/RobertaForSequenceClassification_epoch-3.pt\"\n","best_model, _ = load_model_and_metrics(model, optimizer, best_model_path)\n","\n","# bm25,sbert or dpr (Retrievers)\n","method = 'sbert'\n","k = 4   #find the k nearest evidences\n","\n","for index, row in tqdm(dev_data.iterrows()):\n","    row_loc = dev_data.index.get_loc(index)\n","    claim_text = row['claim_text']\n","    claim_label = ''\n","    label_map = {0: \"SUPPORTS\", 1: \"REFUTES\", 2: \"NOT_ENOUGH_INFO\", 3: \"DISPUTED\"}\n","\n","    # print(f\"{row['claim_text']},{row['evidences']},{row['claim_label']}\")\n","    vote = []\n","\n","    if method == 'sbert':\n","        claim_embedding = claims_embedding[row_loc].unsqueeze(0)\n","        cosine_similarities = util.cos_sim(claim_embedding, SBERT_evidence_embeddings)\n","\n","        top_k_values, top_k_indices = torch.topk(cosine_similarities, k=k, dim=1)\n","        top_k_indices = top_k_indices.squeeze(0).tolist()\n","\n","    elif method == 'bm25':\n","        query_token = claim_text.split(\" \")\n","        scores = bm25.get_scores(query_token)\n","        top_k_indices = np.argsort(scores)[::-1][:k]\n","    \n","    elif method == 'dpr':\n","        dpr_claim_embedding = DPR_claims_embeddings[row_loc].unsqueeze(0)\n","        top_k_indices, _ = find_top_n_evidence(dpr_claim_embedding, DPR_evidence_embeddings, n=k)\n","\n","    for evd_index in top_k_indices:\n","        inputs = tokenizer(claim_text, evidences[evd_index], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n","        best_model.eval()\n","        with torch.no_grad():\n","            outputs = best_model(**inputs)\n","            logits = outputs.logits\n","            predictions = torch.argmax(logits, dim=-1)\n","            vote.append(predictions.item())\n","\n","    \n","    result = check_array(vote)\n","    evd_result = []\n","    if result == 2:\n","        evd_result = top_k_indices\n","    elif result == 0:\n","        evd_locs = [i for i in range(len(vote)) if vote[i] == 0]\n","        evd_result = [top_k_indices[i] for i in evd_locs]\n","    elif result == 1:\n","        evd_locs = [i for i in range(len(vote)) if vote[i] == 1]\n","        evd_result = [top_k_indices[i] for i in evd_locs]\n","    elif result == 3:\n","        evd_locs = [i for i in range(len(vote)) if vote[i] != 2]\n","        evd_result = [top_k_indices[i] for i in evd_locs]\n","\n","    \n","    evd_result = [f'evidence-{num}' for num in evd_result]\n","    claim_label = label_map.get(result)\n","    dev_data_pred.loc[index, 'claim_label'] = claim_label\n","    dev_data_pred.loc[index, 'evidences'] = evd_result\n","print(f'prediction completed on : {method}')\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["dev_data_pred.to_json('data/dev-pred-dpr_roberta_k_5.json',orient='index')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNnozNrVCS8Jrh2Bh6w9H0p","collapsed_sections":["DYRV-S40oYZL","HOsel5yvQMqn","NeKjwrM4oPUt","po-Srxz2zCVV","vfXNXzVoYvsY","tCy3VTk4GTiD","KkFAcy7FHHES","b5v-PBKbrpLV"],"gpuType":"L4","machine_shape":"hm","mount_file_id":"1_ru7gfkgIIWcgpxR-_Skj3lFwClgywMl","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"006938b3be4d46f1afed4df75fc96121":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04fd4148d9734a259798326c35acb802":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c88727a09b94d8a8033f4beed2bb030":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e94996ae09649deb9440e04938df8b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ecd479b7f084fb6859fc7c8f757259d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1d0947e9d04a0a963df84cd960b908","placeholder":"​","style":"IPY_MODEL_a289b021fbe84beba8d7b98ecb5fe741","value":" 48.0/48.0 [00:00&lt;00:00, 3.80kB/s]"}},"22ab6ffa6aff450f9b38609728f1a41b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8337b05dfba542b18af1d9374cca7727","IPY_MODEL_95b7dac8ffe045809fd8899fb7e2713d","IPY_MODEL_cb0d7371eaec47c8b9ae1e4fe159174d"],"layout":"IPY_MODEL_b1620b45ffc94b79aa958acfa2fd0f5d"}},"24c0d5bd34724e77a4f8040673542655":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db0df92d86d4a00841310accc900bb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48e4351fa1eb466cbfcac0d73102c3c7","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96dc0afd458b45d4bcb84920cd8540b9","value":48}},"3d1d90c4067a4aed992f46f31dc47082":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43c4a4cd5d6f46ed9975045e5c6ef79d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e4351fa1eb466cbfcac0d73102c3c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1d0947e9d04a0a963df84cd960b908":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe9150319d8442385b6d1abfcc8b4b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53095e476ee34357908961aef028a2da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86daca5476fc43e89e09e3780a249688","IPY_MODEL_c0c37339d87a4ac8bcee6af538a8b97e","IPY_MODEL_5d680862727c427984ed1cf1a633dc9c"],"layout":"IPY_MODEL_6bd4173bff714866b471a8aaddd432c2"}},"572de2a57015405ab5fa86e99e21299b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59d34d5ca14a442e89e364a2f8829d1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93d77389ac58499589f14c3e66e659fc","placeholder":"​","style":"IPY_MODEL_767cc5ec12b14a8a8683cad02f2688db","value":"config.json: 100%"}},"5d680862727c427984ed1cf1a633dc9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e94996ae09649deb9440e04938df8b3","placeholder":"​","style":"IPY_MODEL_faf3e5328edf4f8f959704c6a5d7573a","value":" 232k/232k [00:00&lt;00:00, 17.3MB/s]"}},"60dda5e87844400aa43e6f3a58e08a5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9153fbcd6040b19f49ccd92b69bf77","placeholder":"​","style":"IPY_MODEL_572de2a57015405ab5fa86e99e21299b","value":" 570/570 [00:00&lt;00:00, 53.8kB/s]"}},"648fafbe3a6a4822891303ea01d9e3d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bd4173bff714866b471a8aaddd432c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f64b9ca87045a3a212a6616e264f8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c0d5bd34724e77a4f8040673542655","placeholder":"​","style":"IPY_MODEL_04fd4148d9734a259798326c35acb802","value":"tokenizer_config.json: 100%"}},"767cc5ec12b14a8a8683cad02f2688db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8337b05dfba542b18af1d9374cca7727":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11de9e3e8b54d959ee8d054b7666e16","placeholder":"​","style":"IPY_MODEL_c2cdfa7f3fc84987b7cb9d3b020b289c","value":"tokenizer.json: 100%"}},"86daca5476fc43e89e09e3780a249688":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fe9150319d8442385b6d1abfcc8b4b6","placeholder":"​","style":"IPY_MODEL_f27a7be4b1fa4995aa76a9c10af40c58","value":"vocab.txt: 100%"}},"93d77389ac58499589f14c3e66e659fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b7dac8ffe045809fd8899fb7e2713d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_006938b3be4d46f1afed4df75fc96121","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd56dc2785c049dd85bb8c559491ee5b","value":466062}},"96dc0afd458b45d4bcb84920cd8540b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f9153fbcd6040b19f49ccd92b69bf77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a289b021fbe84beba8d7b98ecb5fe741":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1620b45ffc94b79aa958acfa2fd0f5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c37339d87a4ac8bcee6af538a8b97e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d1d90c4067a4aed992f46f31dc47082","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c37edaefdd484f198bdeb66d4c2b4bc9","value":231508}},"c2cdfa7f3fc84987b7cb9d3b020b289c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c37edaefdd484f198bdeb66d4c2b4bc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c51bb68701f34118b1192470c4415e45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb0d7371eaec47c8b9ae1e4fe159174d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c4a4cd5d6f46ed9975045e5c6ef79d","placeholder":"​","style":"IPY_MODEL_dea06e904af84aa7a2217d4a3982e4ea","value":" 466k/466k [00:00&lt;00:00, 17.5MB/s]"}},"dc41124288094fadb79e1eb1b46b2515":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59d34d5ca14a442e89e364a2f8829d1b","IPY_MODEL_fcb9516fd61c408c93d3da9de190dfe6","IPY_MODEL_60dda5e87844400aa43e6f3a58e08a5e"],"layout":"IPY_MODEL_0c88727a09b94d8a8033f4beed2bb030"}},"dea06e904af84aa7a2217d4a3982e4ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f11de9e3e8b54d959ee8d054b7666e16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27a7be4b1fa4995aa76a9c10af40c58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f912bc64d9974701aa7c6c65529b2760":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73f64b9ca87045a3a212a6616e264f8a","IPY_MODEL_2db0df92d86d4a00841310accc900bb3","IPY_MODEL_1ecd479b7f084fb6859fc7c8f757259d"],"layout":"IPY_MODEL_648fafbe3a6a4822891303ea01d9e3d8"}},"f9eb5043498c4aaabf4bc482e48260af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faf3e5328edf4f8f959704c6a5d7573a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcb9516fd61c408c93d3da9de190dfe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c51bb68701f34118b1192470c4415e45","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9eb5043498c4aaabf4bc482e48260af","value":570}},"fd56dc2785c049dd85bb8c559491ee5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
